---
title: "Heart Disease"
author: "zhicong Fan (zhicong2@illinois.edu)"
date: "11/08/2020"
output:
  html_document: 
    theme: default
    toc: yes
---

```{r, setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')
```

```{r, load-packages, include = FALSE}
# load packages
```

```{r read-full-data, warning = FALSE, message = FALSE}
# read full data
hd = readr::read_csv("data/hd.csv")
```

***

## Abstract

> Abstract text goes here.
Use different models to analyze Heart Disease based on the UCI dataset
***

## Introduction

I am going to use 4 different models "rpart, knn, gbm, rf" to analyze the heart disease dataset.
***

## Methods

"rpart"
"knn"
"gbm"
"rf"
all using train function while for rpart, knn and gbm we would have additional tune functions

### Data

'age' - age in years
'sex' - sex (1 = male; 0 = female)
'cp' - chest pain type
'trestbps' - resting blood pressure (in mm Hg on admission to the hospital)
'chol' - serum cholestoral in mg/dl
'fbs' - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)
'restecg' - resting electrocardiographic results
'thalach' - maximum heart rate achieved
'exang' - exercise induced angina (1 = yes; 0 = no)
'oldpeak' -  ST depression induced by exercise relative to rest
'slope' -  the slope of the peak exercise ST segment
'ca' -  number of major vessels (0-3) colored by flourosopy
'thal' - 3 = normal; 6 = fixed defect; 7 = reversable defect
'num' - diagnosis of heart disease (angiographic disease status)

### Modeling

hd_tree_mod = train(form = num~., 
                    data = hd_trn_full, 
                    method = "rpart", 
                    trControl = cv_5, 
                    tuneLength = 10)
                    
hd_knn_mod = train(form = num~., 
                    data = hd_trn_full, 
                    method = "knn", 
                    trControl = cv_5, 
                    tuneGrid = hd_knn_tune)

hd_gbm_mod = train(form = num~., 
                   data = hd_trn_full, 
                   method = "gbm", 
                   trControl = cv_5,
                   tuneGrid = hd_gbm_tune,
                   verbose = FALSE)

hd_rf_mod = train(form = num~., 
                   data = hd_trn_full, 
                   method = "rf", 
                   trControl = cv_5,
                   verbose = FALSE)

For all these, we use Cross-Validation

***

## Results

- Tree Model:
  Best cp: 0.01219512
  Best Accuracy: 0.6266667
  Predictions:
  
- KNN Model:
  Best k: 93
  Best Accuracy: 0.5657710
  
- gbm Model:
  Best n.trees = 50
  Best interaction.depth = 1
  Best shrinkage = 0.1
  Best n.minobsinnode = 5
  Best Accuracy:  0.6304990
  
- rf Model:
  Best mtry = 16
  Best Accuracy: 0.6267258

***

## Discussion

As we can see, the gbm model has the highest accuracy.
Then here are all the predictions from gbm model:
            v0         v1          v2          v3          v4
1   0.43159818 0.16903961 0.119459255 0.186948863 0.092954090
2   0.08055706 0.35725495 0.162471701 0.267556528 0.132159758
3   0.05626823 0.23935331 0.362857029 0.165469573 0.176051853
4   0.53907128 0.16252432 0.112969905 0.142538716 0.042895784
5   0.90117869 0.05059693 0.020291954 0.021114923 0.006817502
6   0.86762614 0.08671051 0.025306955 0.017016356 0.003340036
7   0.14467176 0.10733741 0.214982796 0.306011506 0.226996528
8   0.45815966 0.36625093 0.107697536 0.056072004 0.011819875
9   0.31998178 0.34646644 0.179858533 0.092882500 0.060810744
10  0.11154020 0.34375381 0.221367514 0.241350460 0.081988019
11  0.65288996 0.21744871 0.071004775 0.047743496 0.010913055
12  0.86838107 0.05756270 0.034349374 0.030596395 0.009110469
13  0.50960004 0.32722193 0.068774472 0.077276291 0.017127269
14  0.84874096 0.08303461 0.022574655 0.029431686 0.016218086
15  0.72914180 0.14102513 0.065263047 0.053147799 0.011422224
16  0.84537168 0.10274547 0.023826296 0.023974363 0.004082193
17  0.49788346 0.34613822 0.080369531 0.064607806 0.011000981
18  0.90527320 0.05946645 0.016427447 0.016310756 0.002522148
19  0.81794744 0.12952078 0.024222871 0.024158777 0.004150138
20  0.33723175 0.33333253 0.173366930 0.097866648 0.058202145
21  0.08935931 0.51700210 0.166198293 0.157391351 0.070048947
22  0.86722009 0.07814901 0.029611255 0.021379315 0.003640325
23  0.44226943 0.06698827 0.226341904 0.169866996 0.094533392
24  0.43035656 0.41783182 0.068918718 0.065070356 0.017822546
25  0.10799249 0.46330412 0.096306272 0.305562101 0.026835013
26  0.68851254 0.07332041 0.135956361 0.089499293 0.012711392
27  0.17854309 0.50057273 0.196324691 0.110205175 0.014354312
28  0.77294747 0.11040849 0.074498418 0.030829521 0.011316098
29  0.76366830 0.18381659 0.025689727 0.022423934 0.004401457
30  0.10797165 0.45695371 0.087325373 0.267934740 0.079814521
31  0.19468308 0.51052861 0.075805719 0.169733102 0.049249487
32  0.17208334 0.58499347 0.147639618 0.082351899 0.012931673
33  0.46321214 0.27305602 0.136419294 0.100882485 0.026430061
34  0.54519203 0.14110545 0.090332933 0.143521411 0.079848169
35  0.69281401 0.21111484 0.049501711 0.039793649 0.006775794
36  0.63050645 0.18463400 0.101514624 0.068907577 0.014437351
37  0.75916339 0.15543091 0.040589824 0.039581037 0.005234837
38  0.19792144 0.34518949 0.149281621 0.127681511 0.179925943
39  0.75641123 0.12606882 0.045196575 0.059296757 0.013026615
40  0.94628817 0.03282468 0.010217731 0.008918808 0.001750618
41  0.55523701 0.20263930 0.137790297 0.082270170 0.022063225
42  0.92793674 0.04479416 0.010692124 0.012080597 0.004496374
43  0.14262955 0.58537304 0.184363091 0.073553740 0.014080573
44  0.82352312 0.12491189 0.025224938 0.022018231 0.004321824
45  0.63822757 0.23480637 0.045971848 0.064754588 0.016239622
46  0.82887599 0.11384161 0.020065707 0.028778428 0.008438260
47  0.49044360 0.33858273 0.076548775 0.071378493 0.023046404
48  0.73811073 0.13854528 0.043621017 0.066461178 0.013261800
49  0.10476078 0.54804521 0.138793302 0.166841828 0.041558882
50  0.92524209 0.03870442 0.015189240 0.018576317 0.002287935
51  0.39922013 0.33323000 0.127109558 0.128850065 0.011590249
52  0.05764761 0.36751622 0.303844442 0.133142687 0.137849040
53  0.36811573 0.17405992 0.305246307 0.083650825 0.068927213
54  0.73899527 0.16005433 0.037841367 0.041536347 0.021572687
55  0.04134242 0.16372481 0.370510260 0.187547159 0.236875353
56  0.36227561 0.12783395 0.147871826 0.243445315 0.118573290
57  0.83097131 0.07673783 0.043679800 0.031057117 0.017553937
58  0.43550179 0.25391690 0.172454105 0.118849951 0.019277259
59  0.05730187 0.59166445 0.179254390 0.154481863 0.017297427
60  0.42446456 0.36749175 0.093971286 0.065008976 0.049063436
61  0.74396218 0.18037891 0.029665616 0.033517974 0.012475322
62  0.80093663 0.05782221 0.049707507 0.031542470 0.059991178
63  0.05744156 0.41850310 0.326148893 0.109531314 0.088375131
64  0.82875018 0.08237112 0.041062081 0.036845426 0.010971198
65  0.89752132 0.06899389 0.013129278 0.014834237 0.005521273
66  0.14942438 0.53842638 0.081200376 0.179008144 0.051940719
67  0.12616861 0.41807456 0.225533870 0.132853294 0.097369664
68  0.75069919 0.15692598 0.036458255 0.042177493 0.013739084
69  0.90952885 0.05474999 0.014517987 0.015784990 0.005418175
70  0.87096418 0.07499450 0.030052691 0.020311843 0.003676788
71  0.89571391 0.07086873 0.013102838 0.014804364 0.005510155
72  0.89637657 0.05185816 0.015717782 0.030124334 0.005923156
73  0.90007828 0.06358624 0.013400425 0.017299755 0.005635299
74  0.06281189 0.02600708 0.112345623 0.313310890 0.485524518
75  0.52967560 0.22002836 0.167474640 0.066064081 0.016757323
76  0.92912511 0.04175206 0.013047195 0.014197885 0.001877758
77  0.88465157 0.05660174 0.028001180 0.017521628 0.013223886
78  0.35007751 0.53346491 0.056969567 0.049727342 0.009760676
79  0.26305360 0.24140881 0.202968219 0.122590533 0.169978839
80  0.84783132 0.09706677 0.026955154 0.023528494 0.004618264
81  0.78860034 0.14365666 0.026561813 0.030011113 0.011170076
82  0.71234385 0.21156733 0.028061349 0.036226796 0.011800678
83  0.88160187 0.07405962 0.019257959 0.018277643 0.006802902
84  0.77156552 0.12605101 0.043497275 0.042069973 0.016816222
85  0.76180518 0.07312538 0.057586367 0.069875742 0.037607332
86  0.64640084 0.18900257 0.082877428 0.072310634 0.009408536
87  0.85354340 0.09320572 0.026732055 0.022454230 0.004064597
88  0.35155751 0.42290639 0.125745274 0.086873505 0.012917322
89  0.83580646 0.10020504 0.028469677 0.024778857 0.010739963
90  0.04097210 0.22493391 0.331049092 0.293647745 0.109397150
91  0.18382462 0.54101647 0.130740730 0.118406122 0.026012062
92  0.92222640 0.04864843 0.012650207 0.012006255 0.004468704
93  0.14402628 0.26414273 0.337736706 0.174050690 0.080043595
94  0.61922235 0.17638926 0.103275989 0.090016369 0.011096031
95  0.84535838 0.09647021 0.030051427 0.023506118 0.004613872
96  0.81891986 0.10228918 0.044011067 0.029719466 0.005060430
97  0.06813702 0.41826483 0.304893100 0.151988053 0.056716996
98  0.10860808 0.28142239 0.327018880 0.106262066 0.176688586
99  0.29554691 0.51407116 0.063705069 0.103694368 0.022982486
100 0.06538031 0.03865461 0.132761836 0.254424582 0.508778669
101 0.03911643 0.15542063 0.111026531 0.607567591 0.086868819
102 0.60409912 0.17557438 0.092670357 0.094494865 0.033161277
103 0.80528216 0.13179788 0.024833087 0.028728675 0.009358206
104 0.71410723 0.21640734 0.033991388 0.029670251 0.005823792
105 0.92793674 0.04479416 0.010692124 0.012080597 0.004496374
106 0.49473476 0.39400329 0.041033101 0.052973141 0.017255707
107 0.94458944 0.03456090 0.010199389 0.008902797 0.001747476
108 0.85650081 0.08303126 0.025443822 0.026475732 0.008548379
109 0.04518506 0.16818751 0.351704137 0.209339251 0.225584047
110 0.44619410 0.23548205 0.126464545 0.158509096 0.033350206
111 0.20250219 0.57925680 0.124200983 0.080357333 0.013682704
112 0.69669609 0.19688016 0.063481261 0.035179287 0.007763201
113 0.73971402 0.12402440 0.035894612 0.038718003 0.061648965
114 0.91883641 0.04822465 0.014655569 0.016129273 0.002154092
115 0.24912033 0.38226786 0.239194399 0.100383165 0.029034239
116 0.84965097 0.10823988 0.020599262 0.017980592 0.003529300
117 0.32466450 0.29932011 0.086162626 0.146875469 0.142977291
118 0.87251562 0.09640451 0.015203876 0.013271091 0.002604901
119 0.87058775 0.07496209 0.022129936 0.024061242 0.008258986
120 0.80878727 0.09794153 0.038736885 0.045727317 0.008807000
121 0.61303664 0.26136489 0.046430532 0.061670861 0.017497079
122 0.66670467 0.09171775 0.145055497 0.065731004 0.030791083
123 0.28590965 0.43424627 0.070836951 0.107849432 0.101157697
124 0.05132737 0.47686570 0.120593554 0.298400884 0.052812484
125 0.10105180 0.16906977 0.166384979 0.371024697 0.192468753
126 0.57938605 0.25809066 0.072701998 0.064170888 0.025650405
127 0.85441188 0.09056569 0.024481214 0.026942944 0.003598276
128 0.31573033 0.27518930 0.140333472 0.146574764 0.122172131
129 0.85888010 0.08701438 0.029326485 0.021173712 0.003605317
130 0.49491180 0.32197691 0.081362689 0.076647627 0.025100972
131 0.83510082 0.11668661 0.021451289 0.023608343 0.003152935
132 0.45691950 0.39470969 0.081250413 0.054632646 0.012487755
133 0.88766223 0.07597043 0.017790438 0.015528838 0.003048061
134 0.79233393 0.11858219 0.027574753 0.049863643 0.011645483
135 0.33907711 0.51670197 0.050519793 0.072455967 0.021245159
136 0.93210469 0.03166924 0.017216762 0.016788870 0.002220432
137 0.07441975 0.14191903 0.262611331 0.252036003 0.269013884
138 0.35588659 0.40798767 0.060298515 0.148962627 0.026864597
139 0.45626897 0.32678603 0.102143335 0.060089271 0.054712395
140 0.50717381 0.19746804 0.177485589 0.079198344 0.038674218
141 0.22181937 0.29626982 0.181415224 0.175401121 0.125094465
142 0.08899260 0.55549062 0.142712748 0.196187312 0.016616717
143 0.57873422 0.28102342 0.066216523 0.065304329 0.008721505
144 0.10620906 0.48741201 0.133158269 0.242827478 0.030393180
145 0.81889474 0.11906835 0.022272693 0.031729038 0.008035183
146 0.60530492 0.28629305 0.037972635 0.054460714 0.015968685
147 0.25833422 0.42255898 0.169164750 0.113570243 0.036371801
148 0.13323724 0.05221265 0.078623934 0.255931398 0.479994777
149 0.70553883 0.13770138 0.070115199 0.051098479 0.035546116
150 0.94212737 0.02317778 0.020703096 0.010008324 0.003983425
151 0.85339319 0.10047089 0.020527321 0.022591464 0.003017129
152 0.47599943 0.21321624 0.139808217 0.111876895 0.059099217
153 0.39173400 0.17621701 0.182624196 0.203353527 0.046071272
154 0.87028515 0.08949422 0.019675419 0.017174192 0.003371017
155 0.04085601 0.18182506 0.152672879 0.513100295 0.111545763
156 0.31808726 0.48299153 0.076512139 0.097673785 0.024735281
157 0.26840904 0.22678802 0.242533873 0.241693363 0.020575711
158 0.64391240 0.08783767 0.114918135 0.127019193 0.026312595
159 0.60097839 0.09492513 0.099757227 0.124943855 0.079395403
160 0.64662653 0.23199376 0.047592590 0.053772935 0.020014178
161 0.90429422 0.05953563 0.016610509 0.016713734 0.002845902
162 0.74739605 0.17993152 0.028494628 0.032194923 0.011982886
163 0.58733515 0.15181588 0.116832177 0.057274870 0.086741924
164 0.83648589 0.08056423 0.033848881 0.042018194 0.007082814
165 0.87809123 0.04572802 0.046735484 0.021539212 0.007906053
166 0.66533608 0.24477970 0.043970219 0.038380528 0.007533479
167 0.41374966 0.36999605 0.086342568 0.098804968 0.031106758
168 0.29816879 0.48069269 0.077968503 0.106880318 0.036289702
169 0.83421994 0.11794375 0.022057744 0.021999379 0.003779184
170 0.94458944 0.03456090 0.010199389 0.008902797 0.001747476
171 0.68375850 0.18155501 0.046920839 0.070397092 0.017368566
172 0.50775839 0.15225098 0.135303547 0.122010605 0.082676475
173 0.68383611 0.22378038 0.045192835 0.039447720 0.007742952
174 0.67250197 0.18561867 0.067578068 0.058593145 0.015708147
175 0.63460209 0.24627535 0.046707575 0.052772991 0.019642001
176 0.34249859 0.23501978 0.213013382 0.172839877 0.036628375
177 0.63681871 0.24342831 0.054169508 0.049323814 0.016259666
178 0.91040216 0.06105618 0.010526084 0.013589023 0.004426549
179 0.06715789 0.60696715 0.076741007 0.239132022 0.010001931
180 0.22838466 0.46325005 0.181729127 0.101546647 0.025089516
181 0.95970252 0.02349172 0.008221163 0.007176052 0.001408543
182 0.67457612 0.21549526 0.056789264 0.044420358 0.008719000
183 0.87261620 0.04578168 0.041352085 0.030070284 0.010179750
184 0.26933870 0.35467056 0.195014158 0.118470492 0.062506090
185 0.12998300 0.13263340 0.362731603 0.266390883 0.108261105
186 0.74448200 0.15091024 0.040564602 0.051202279 0.012840876
187 0.63919554 0.12089772 0.080269267 0.098532370 0.061105110
188 0.93862867 0.03389862 0.010612768 0.010973949 0.005885996
189 0.05614716 0.35048458 0.161691412 0.377657946 0.054018902
190 0.09144191 0.53731957 0.117983756 0.232922502 0.020332259
191 0.49132321 0.35986043 0.062283782 0.063061292 0.023471286
192 0.86556096 0.08407179 0.023475045 0.022770377 0.004121825
193 0.86145520 0.09585062 0.020885448 0.018230397 0.003578333
194 0.93428762 0.03642212 0.013651536 0.013241748 0.002396981
195 0.76391138 0.16358184 0.031810522 0.035246120 0.005450141
196 0.41357491 0.16484019 0.278467367 0.086765125 0.056352407
197 0.19466771 0.25938611 0.253558595 0.266592587 0.025794996
198 0.53487443 0.33547482 0.073921642 0.045360703 0.010368404
199 0.62997581 0.25700423 0.051902449 0.052224992 0.008892519
200 0.77629369 0.08162692 0.071017333 0.050209483 0.020852568
***

## Appendix

Place potential additional information here.
