knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')
# load packages
library("tidyverse")
library("caret")
library("rpart")
library("rpart.plot")
library("PRROC")
library("ROCR")
library("MLmetrics")
# read data and subset
source("make-data.R")
# read full data
cc = data.table::fread("data/cc.csv.gz")
# read subset of data
cc_sub = data.table::fread("data/cc-sub.csv")
# Creating Train/Test dataset
set.seed((42))
trn_idx = createDataPartition(cc$Class, p = 0.80, list = TRUE)
cc_trn = cc[trn_idx$Resample1, ]
cc_tst = cc[-trn_idx$Resample1, ]
# Creating Estimation/Validation dataset
trn_idx_sub = createDataPartition(cc_sub$Class, p = 0.80, list = TRUE)
cc_trn_sub = cc_sub[trn_idx_sub$Resample1, ]
cc_tst_sub = cc_sub[-trn_idx_sub$Resample1, ]
table(cc_trn$Class)
cc_trn_full = na.omit(cc_trn_sub)
est_idx = createDataPartition(cc_trn_sub$Class, p = 0.80, list = TRUE)
cc_est = cc_trn_sub[est_idx$Resample1, ]
cc_val = cc_trn_sub[-est_idx$Resample1, ]
table(cc_est$Class)
table(cc_val$Class)
# establishing first baseline
table(
actual = cc_val$Class,
predicted = rep("fraud", length(cc_val$Class))
)
mod = rpart(Class~., data = cc_est, cp = 0)
table(
actual = cc_val$Class,
predicted = predict(mod, cc_val, type = "class")
)
sum(predict(mod, cc_val, type = "class")==cc_val$Class & (cc_val$Class == "fraud")) / 78
sum(predict(mod, cc_val, type = "class")==cc_val$Class & (cc_val$Class == "fraud")) / 78
PRAUC(y_pred = predict(mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
cc_tree_tune = expand.grid(
cp = c(0, 0.0001, 0.001, 0.01, 0.1, 1)
)
hd_knn_tune = expand.grid(
k = 1:100
)
c_tree_mod = train(form = Class~.,
data = cc_est,
method = "rpart")
PRAUC(y_pred = predict(c_tree_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
cc_knn_mod = train(form = Class~.,
data = cc_est,
method = "knn")
PRAUC(y_pred = predict(cc_knn_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
PRAUC
c_tree_mod
cc_knn_mod
PRAUC(y_pred = predict(cc_knn_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
tree_mod = rpart(Class~., data = cc_est, cp = 0)
PRAUC(y_pred = predict(tree_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
knn_mod = knnreg(Class~., data = cc_est, k = 9)
PRAUC(y_pred = predict(knn_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
tree_mod = rpart(Class~., data = cc_est, cp = 0)
PRAUC(y_pred = predict(tree_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
knn_mod = knn(Class~., data = cc_est, k = 9)
tree_mod = rpart(Class~., data = cc_est, cp = 0)
PRAUC(y_pred = predict(tree_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
knn_mod = knn3(Class~., data = cc_est, k = 9)
PRAUC(y_pred = predict(knn_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
cc_trn_full = na.omit(cc_trn)
est_idx = createDataPartition(cc_trn$Class, p = 0.80, list = TRUE)
cc_est = cc_trn[est_idx$Resample1, ]
cc_val = cc_trn[-est_idx$Resample1, ]
table(cc_est$Class)
table(cc_val$Class)
# establishing first baseline
table(
actual = cc_val$Class,
predicted = rep("fraud", length(cc_val$Class))
)
mod = rpart(Class~., data = cc_est, cp = 0)
table(
actual = cc_val$Class,
predicted = predict(mod, cc_val, type = "class")
)
PRAUC(y_pred = predict(mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
PRAUC(y_pred = predict(mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
best_knn_mod = knn3(Class~., data = cc_est, k = 9)
table(
actual = cc_val$Class,
predicted = predict(best_knn_mod, cc_val, type = "class")
)
PRAUC(y_pred = predict(best_knn_mod, cc_val, type = "prob")[, 1], y_true = cc_val$Class)
View(best_knn_mod)
View(best_knn_mod)
